{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29821,"status":"ok","timestamp":1711289042638,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"},"user_tz":-330},"id":"uM2RNn7hPq09","outputId":"2cce9eea-0141-4435-9407-7e51de061bb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","\n","import pathlib\n","import random\n","import string\n","import re\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow.data as tf_data\n","import tensorflow.strings as tf_strings\n","\n","import keras\n","from keras import layers\n","#from keras import ops\n","from keras.layers import TextVectorization\n","\n","from sklearn.metrics import accuracy_score\n","from google.colab import drive as dr\n","dr.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"H3LPHtW9Pq0-","executionInfo":{"status":"ok","timestamp":1711289043029,"user_tz":-330,"elapsed":395,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["barnette_graphs=np.load('drive/My Drive/Minor Work/Datasets/barnette_graph_data_alpha.npy',allow_pickle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1711159282567,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"wqwLQHvHPq0-","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"4fb814ce-048a-4a12-ed87-70612563c7ec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'13.14.15.16 5.6.2.1 2.6.8.4.10.9 3.4.8.7 5.1.12.11.3.7 5.6.8.7 10.4.3.11.14.13 12.1.2.9.16.15 14.11.12.15 16.9.10.13'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["barnette_graphs[2]"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"PozssstCPq0_","executionInfo":{"status":"ok","timestamp":1711289043849,"user_tz":-330,"elapsed":440,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["\n","hamiltonian_cycles=np.load('drive/My Drive/Minor Work/Datasets/hamiltonian_data_alpha.npy',allow_pickle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100,"status":"ok","timestamp":1711159283651,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"owTo53aMPq0_","outputId":"a965a5af-cf21-499c-e94c-b4249dddf287"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 0., 1., 0., 1., 0., 1., 0., 0., 0.])"]},"metadata":{},"execution_count":5}],"source":["hamiltonian_cycles[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":100,"status":"ok","timestamp":1711159283651,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"nLzWW8j3Pq1A","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aae79784-8fb2-4996-f6e6-bd08362bee5c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["50000"]},"metadata":{},"execution_count":6}],"source":["len(barnette_graphs)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":84,"status":"ok","timestamp":1711159283651,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"oCOT-pEdPq1A","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5e4d6811-58bb-4795-e63d-4170eda4610b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["50000"]},"metadata":{},"execution_count":7}],"source":["len(hamiltonian_cycles)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"aG4_IJEePq1A","executionInfo":{"status":"ok","timestamp":1711289043850,"user_tz":-330,"elapsed":4,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["max_barnette_len=0\n","for j in range(len(barnette_graphs)):\n","    if len(barnette_graphs[j])>max_barnette_len:\n","        max_barnette_len=len(barnette_graphs[j])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":67,"status":"ok","timestamp":1711159283651,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"WzgIIXiPPq1A","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4bbdc250-ae89-402e-892c-769ba832fcc7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["368"]},"metadata":{},"execution_count":9}],"source":["max_barnette_len"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"R9IjyZR_Pq1A","executionInfo":{"status":"ok","timestamp":1711289044235,"user_tz":-330,"elapsed":388,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["barnette_vocab=[\n","'0',\n","'1',\n","'2',\n","'3',\n","'4',\n","'5',\n","'6',\n","'7',\n","'8',\n","'9',\n","' ',\n","'.',\n","'p',\n","''\n","]"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"yv-SdLfAPq1B","executionInfo":{"status":"ok","timestamp":1711289045108,"user_tz":-330,"elapsed":3,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["barnette_vocab_dict={}\n","for i in range(len(barnette_vocab)):\n","    barnette_vocab_dict[barnette_vocab[i]]=i"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"RGB5OgmvPq1B","executionInfo":{"status":"ok","timestamp":1711289046473,"user_tz":-330,"elapsed":6,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["barnette_vocab_rev_dict={}\n","for i in range(len(barnette_vocab)):\n","    barnette_vocab_rev_dict[i]=barnette_vocab[i]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":50,"status":"ok","timestamp":1711159283651,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"uNuZmxPEYOvh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e05ca58-50f2-47dd-f665-d1426fc47465"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'0': 0,\n"," '1': 1,\n"," '2': 2,\n"," '3': 3,\n"," '4': 4,\n"," '5': 5,\n"," '6': 6,\n"," '7': 7,\n"," '8': 8,\n"," '9': 9,\n"," ' ': 10,\n"," '.': 11,\n"," 'p': 12,\n"," '': 13}"]},"metadata":{},"execution_count":13}],"source":["barnette_vocab_dict"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"lTAjZUmHPq1C","executionInfo":{"status":"ok","timestamp":1711289048172,"user_tz":-330,"elapsed":4,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["def text_to_numeric(data,vocab_dict,max_len):\n","    data_numeric=[]\n","    for i in range(len(data)):\n","        numeric=[]\n","\n","        for char in data[i]:\n","            numeric.append(vocab_dict[char])\n","\n","        count=len(numeric)\n","\n","        while count<=max_len:\n","            numeric.append(vocab_dict['p'])\n","            count=count+1\n","        data_numeric.append(np.array(numeric))\n","\n","    return np.array(data_numeric)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"D3UgvamaPq1D","executionInfo":{"status":"ok","timestamp":1711289056272,"user_tz":-330,"elapsed":4675,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["barnette_graphs_numeric=text_to_numeric(barnette_graphs,barnette_vocab_dict, 400)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1650,"status":"ok","timestamp":1711159299451,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"bxH8RhJnPq1D","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d7bcdb1-47ca-4aa1-8e1d-1773bc2f32a4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 401)"]},"metadata":{},"execution_count":16}],"source":["barnette_graphs_numeric.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711159300068,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"go88HrdEyuH4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f9dd920a-ea1a-4023-abfc-b917b84d90fc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1,  3, 11,  1,  4, 11,  1,  5, 11,  1,  6, 10,  5, 11,  6, 11,  2,\n","       11,  1, 10,  2, 11,  6, 11,  8, 11,  4, 11,  1,  0, 11,  9, 10,  3,\n","       11,  4, 11,  8, 11,  7, 10,  5, 11,  1, 11,  1,  2, 11,  1,  1, 11,\n","        3, 11,  7, 10,  5, 11,  6, 11,  8, 11,  7, 10,  1,  0, 11,  4, 11,\n","        3, 11,  1,  1, 11,  1,  4, 11,  1,  3, 10,  1,  2, 11,  1, 11,  2,\n","       11,  9, 11,  1,  6, 11,  1,  5, 10,  1,  4, 11,  1,  1, 11,  1,  2,\n","       11,  1,  5, 10,  1,  6, 11,  9, 11,  1,  0, 11,  1,  3, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n","       12, 12, 12, 12, 12, 12, 12, 12, 12, 12])"]},"metadata":{},"execution_count":17}],"source":["barnette_graphs_numeric[2]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"T21p_C1RyuH4","executionInfo":{"status":"ok","timestamp":1711289057253,"user_tz":-330,"elapsed":6,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["max_hamiltonian_len=0\n","for i in range(len(hamiltonian_cycles)):\n","    if len(hamiltonian_cycles[i])>max_hamiltonian_len:\n","        max_hamiltonian_len=len(hamiltonian_cycles[i])"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"uGUiBd9iyuH4","executionInfo":{"status":"ok","timestamp":1711289061261,"user_tz":-330,"elapsed":583,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["#hamiltonian_cycles_padded=np.zeros((len(hamiltonian_cycles),max_hamiltonian_len))-1\n","hamiltonian_cycles_padded=np.zeros((len(hamiltonian_cycles),max_hamiltonian_len))\n","for i in range(len(hamiltonian_cycles)):\n","    for j in range(len(hamiltonian_cycles[i])):\n","        hamiltonian_cycles_padded[i][j]=hamiltonian_cycles[i][j]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711038671722,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"vuXLS1qwyuH4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8ab2564-b422-47a7-f31a-e6e9143623a5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0.])"]},"metadata":{},"execution_count":23}],"source":["hamiltonian_cycles_padded[2]"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":369,"status":"ok","timestamp":1711289064940,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"},"user_tz":-330},"id":"K-jhZ2rTPq1D","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c8cb166-8493-4e15-8233-9bca4fd4014e"},"outputs":[{"output_type":"stream","name":"stdout","text":["50000 total samples\n","40000 training samples\n","10000 test samples\n"]}],"source":["num_train_samples = int(0.8 * len(hamiltonian_cycles))\n","\n","barnette_graphs_trn = barnette_graphs_numeric[:num_train_samples]\n","hamiltonian_cycles_trn = hamiltonian_cycles_padded[:num_train_samples]\n","\n","barnette_graphs_tst = barnette_graphs_numeric[num_train_samples:]\n","hamiltonian_cycles_tst = hamiltonian_cycles_padded[num_train_samples:]\n","\n","\n","print(f\"{len(hamiltonian_cycles)} total samples\")\n","print(f\"{len(hamiltonian_cycles_trn)} training samples\")\n","print(f\"{len(hamiltonian_cycles_tst)} test samples\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711038672572,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"JOo2mAe34gPH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8d41145-85f5-4489-e096-664153574631"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(40000, 401)"]},"metadata":{},"execution_count":25}],"source":["barnette_graphs_trn.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711038673222,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"TIh4zU1e4gPH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"468cbf3b-423c-47d2-bb0c-0eb35eee66d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(40000, 24)"]},"metadata":{},"execution_count":26}],"source":["hamiltonian_cycles_trn.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1J0GTVp4gPH"},"outputs":[],"source":["def cv_data_split(barnette_graphs_numeric, hamiltonian_cycles_numeric, cv=10):\n","\n","\n","    data_length=len(barnette_graphs_numeric)\n","    r=int(data_length/cv)\n","    division_ranges=(np.arange(cv))*r\n","    folds_data=[]\n","    folds_labels=[]\n","    for i in range(cv-1):\n","        starting_point=int(division_ranges[i])\n","        ending_point=int(division_ranges[i+1])\n","        folds_data.append(barnette_graphs_numeric[starting_point:ending_point])\n","        folds_labels.append(hamiltonian_cycles_numeric[starting_point:ending_point])\n","    folds_data.append(barnette_graphs_numeric[ending_point:])\n","    folds_labels.append(hamiltonian_cycles_numeric[ending_point:])\n","\n","    training_folds_data=[]\n","    training_folds_labels=[]\n","    for i in range(cv):\n","        training_folds_data_temp=[]\n","        training_folds_labels_temp=[]\n","        for j in range(cv):\n","            if j!=i:\n","                for k in range(len(folds_data[j])):\n","                    training_folds_data_temp.append(folds_data[j][k])\n","                    training_folds_labels_temp.append(folds_labels[j][k])\n","        training_folds_data.append(training_folds_data_temp)\n","        training_folds_labels.append(training_folds_labels_temp)\n","\n","    testing_folds_data=folds_data\n","    testing_folds_labels=folds_labels\n","    return np.array(training_folds_data), np.array(training_folds_labels), np.array(testing_folds_data), np.array(testing_folds_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N7MdREAq4gPH"},"outputs":[],"source":["training_folds_data, training_folds_labels, testing_folds_data, testing_folds_labels =cv_data_split(barnette_graphs_trn, hamiltonian_cycles_trn, cv=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711026473028,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"BbOU3M6m4gPH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fde57ced-719b-4e70-8c7f-4ba8a1e5489b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 36000, 401)"]},"metadata":{},"execution_count":32}],"source":["training_folds_data.shape"]},{"cell_type":"code","source":["np.save('Training_data', training_folds_data)\n","np.save('Training_label', training_folds_labels)\n","np.save('Testing_data', testing_folds_data)\n","np.save('Testing_label', testing_folds_labels)"],"metadata":{"id":"evjrGJZ0IFSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":617,"status":"ok","timestamp":1711026828702,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"6RwG2JXH4gPH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eee8a0a3-f00c-4e68-e118-79002abf1ad6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 36000, 24)"]},"metadata":{},"execution_count":34}],"source":["training_folds_labels.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711026830685,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"2TvfMrCK4gPX","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"607fb61c-5907-41cc-a111-e2ac91f11efa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 4000, 401)"]},"metadata":{},"execution_count":35}],"source":["testing_folds_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":433,"status":"ok","timestamp":1711026831718,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"},"user_tz":0},"id":"w8JqkFb94gPX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8810e9cb-0063-423a-be8b-fe67697e32f0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 4000, 24)"]},"metadata":{},"execution_count":36}],"source":["testing_folds_labels.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vXPY2TQb4gPX"},"outputs":[],"source":["class Barnette_Graph(object):\n","    def __init__(self, face_vertex_dict):\n","\n","        # states can be defined as path connected subsets of the set of faces such that,\n","            # 1. have no points in thier interior\n","            # 2. the complement of the set of faces contained in a state is also path connected\n","\n","        # face_vertex_dict is a dictionary whose keys are faces and values are the vertex indices of the corresponding key face\n","        # we input\n","\n","        self.face_vertex_dict=face_vertex_dict\n","\n","    def string_to_list(self,string):\n","        l=string.split('.')\n","        return(l)\n","\n","    def vertices_in_state(self, state):\n","        state_list=self.string_to_list(state)\n","        vertices_in_state=[]\n","        for face in state_list:\n","            vertices_in_face=self.face_vertex_dict[face]\n","            for vertex in vertices_in_face:\n","                vertices_in_state.append(vertex)\n","        return vertices_in_state\n","\n","    def boundary_and_interior(self, state):\n","        vertices_in_state=self.vertices_in_state(state)\n","        unique, counts = np.unique(np.array(vertices_in_state), return_counts=True)\n","        boundary_vertex_list=unique[counts<3]\n","        interior_vertex_list=unique[counts>=3]\n","        return boundary_vertex_list, interior_vertex_list\n","\n","    def nebs_of_face(self, face):\n","        face_vertices=set(self.face_vertex_dict[face])\n","        nebs=[]\n","        for key in self.face_vertex_dict.keys():\n","            neb_vertices=set(self.face_vertex_dict[key])\n","            if len(face_vertices.intersection(neb_vertices))==2:\n","                nebs.append(key)\n","        return nebs\n","\n","    def is_valid_state(self,state,face):\n","        ## by construction a state is path connected\n","        ## check how many vertices in the interior\n","        newState=state+'.'+face\n","        _,interior_vertices=self.boundary_and_interior(newState)\n","\n","\n","        ## check whether complement is path connected\n","        vertices_in_state=self.vertices_in_state(state)\n","        state_vertices=set(vertices_in_state)\n","        face_vertices=set(self.face_vertex_dict[face])\n","\n","        if len(face_vertices.intersection(state_vertices))>2:\n","            return False\n","        elif len(interior_vertices)>0:\n","            return False\n","        else:\n","            return True\n","\n","        return (succ)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"RUcc7TVWPq1D","executionInfo":{"status":"ok","timestamp":1711289079610,"user_tz":-330,"elapsed":3,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["\n","#import keras.ops as ops\n","\n","class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [\n","                layers.Dense(dense_dim, activation=\"relu\"),\n","                layers.Dense(embed_dim),\n","            ]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:,tf.newaxis, tf.newaxis, :], dtype='int32')\n","            #ops.cast(mask[:, None, :], dtype=\"int32\")\n","        else:\n","            padding_mask = None\n","\n","        attention_output = self.attention(\n","            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n","        )\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)\n","\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"embed_dim\": self.embed_dim,\n","                \"dense_dim\": self.dense_dim,\n","                \"num_heads\": self.num_heads,\n","            }\n","        )\n","        return config\n","\n","\n","class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=vocab_size, output_dim=embed_dim\n","        )\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=embed_dim\n","        )\n","        self.sequence_length = sequence_length\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        #ops.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        #ops.arange(0, length, 1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        if mask is None:\n","            return None\n","        else:\n","            return tf.math.not_equal(inputs,0)\n","        #ops.not_equal(inputs, 0)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"sequence_length\": self.sequence_length,\n","                \"vocab_size\": self.vocab_size,\n","                \"embed_dim\": self.embed_dim,\n","            }\n","        )\n","        return config\n","\n","\n","class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.latent_dim = latent_dim\n","        self.num_heads = num_heads\n","        self.attention_1 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.attention_2 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [\n","                layers.Dense(latent_dim, activation=\"relu\"),\n","                layers.Dense(embed_dim),\n","            ]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.layernorm_3 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, encoder_outputs, mask=None):\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, None, :], dtype=\"int32\")\n","            #ops.cast(mask[:, None, :], dtype=\"int32\")\n","            padding_mask = tf.minimum(padding_mask, causal_mask)\n","            #ops.minimum(padding_mask, causal_mask)\n","        else:\n","            padding_mask = None\n","\n","        attention_output_1 = self.attention_1(\n","            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n","        )\n","        out_1 = self.layernorm_1(inputs + attention_output_1)\n","\n","        attention_output_2 = self.attention_2(\n","            query=out_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","            attention_mask=padding_mask,\n","        )\n","        out_2 = self.layernorm_2(out_1 + attention_output_2)\n","\n","        proj_output = self.dense_proj(out_2)\n","        return self.layernorm_3(out_2 + proj_output)\n","\n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        #ops.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = tf.range(sequence_length)[:, None]\n","        #ops.arange(sequence_length)[:, None]\n","        j = tf.range(sequence_length)\n","        #ops.arange(sequence_length)\n","        mask = tf.cast(i >= j, dtype=\"int32\")\n","        #ops.cast(i >= j, dtype=\"int32\")\n","        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        #ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        #mult = ops.concatenate(\n","        #    [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n","        #    axis=0,\n","        #)\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1), tf.convert_to_tensor([1, 1])],\n","            axis=0,\n","        )\n","        return tf.tile(mask, mult)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"embed_dim\": self.embed_dim,\n","                \"latent_dim\": self.latent_dim,\n","                \"num_heads\": self.num_heads,\n","            }\n","        )\n","        return config\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"SRZt4eiJyuH5","executionInfo":{"status":"ok","timestamp":1711289082448,"user_tz":-330,"elapsed":1519,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[],"source":["embed_dim = 256\n","latent_dim = 2048\n","num_heads = 2\n","\n","barnette_graph = keras.Input(shape=(barnette_graphs_trn.shape[1],), dtype=\"int64\")\n","x_1 = PositionalEmbedding(2*max_barnette_len, len(barnette_vocab), embed_dim)(barnette_graph)\n","x_2 = TransformerEncoder(embed_dim, latent_dim, num_heads)(x_1)\n","x_3 = keras.layers.Flatten()(x_2)\n","x_4 = keras.layers.Dense(132, activation='relu')(x_3)\n","hamiltonian_cycle = keras.layers.Dense(hamiltonian_cycles_padded[0].shape[0], activation='sigmoid')(x_4)\n","model = keras.Model(inputs=barnette_graph, outputs=hamiltonian_cycle)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFLthSk5yuH6","outputId":"b28aea98-7b49-479e-dab2-ce490f771bc0","executionInfo":{"status":"ok","timestamp":1711289082448,"user_tz":-330,"elapsed":14,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 401)]             0         \n","                                                                 \n"," positional_embedding (Posi  (None, 401, 256)          192000    \n"," tionalEmbedding)                                                \n","                                                                 \n"," transformer_encoder (Trans  (None, 401, 256)          1577984   \n"," formerEncoder)                                                  \n","                                                                 \n"," flatten (Flatten)           (None, 102656)            0         \n","                                                                 \n"," dense_2 (Dense)             (None, 132)               13550724  \n","                                                                 \n"," dense_3 (Dense)             (None, 24)                3192      \n","                                                                 \n","=================================================================\n","Total params: 15323900 (58.46 MB)\n","Trainable params: 15323900 (58.46 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","source":["X_train, Y_train, X_test, Y_test = np.load('drive/My Drive/Minor Work/Datasets/Modified CV/Training_data.npy'), np.load('drive/My Drive/Minor Work/Datasets/Modified CV/Training_label.npy'), np.load('drive/My Drive/Minor Work/Datasets/Modified CV/Testing_data.npy'), np.load('drive/My Drive/Minor Work/Datasets/Modified CV/Testing_label.npy')"],"metadata":{"id":"ifoXe21OJhEn","executionInfo":{"status":"ok","timestamp":1711289099795,"user_tz":-330,"elapsed":16393,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["#1st fold\n","epochs = 30 # This should be at least 30 for convergence\n","\n","fold_wise_binary_accuracy=[]\n","fold_wise_exact_match=[]\n","\n","#for i in range(1):\n","for i in range(0, 1):\n","    model.compile(keras.optimizers.Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","\n","    model.fit(X_train[i],Y_train[i], epochs= epochs, validation_split=0.1)\n","\n","    print('Model training done for fold '+str(i))\n","    predictions=model.predict(X_test[i])\n","    print('Predictions done for fold '+str(i))\n","\n","    bins = np.array([0.5])\n","    count_exact_match=0\n","    sum_acc=0\n","\n","    for j in range(len(predictions)):\n","        discrete_prediction=np.digitize(predictions[j], bins)\n","        acc=accuracy_score(Y_test[i][j],discrete_prediction)\n","        sum_acc=sum_acc+acc\n","        if acc==1:\n","            count_exact_match=count_exact_match+1\n","    avg_acc=sum_acc/len(predictions)\n","    exact_match_ratio=count_exact_match/len(predictions)\n","\n","    fold_wise_binary_accuracy.append(avg_acc)\n","    fold_wise_exact_match.append(exact_match_ratio)\n","\n","    print('for fold '+ str(i)+' binary accuracy is: ', avg_acc)\n","    print('for fold '+ str(i)+' exact match ratio is: ', exact_match_ratio)\n"],"metadata":{"id":"sdGw2yMF7PHr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711291167467,"user_tz":-330,"elapsed":2064838,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}},"outputId":"40fbf9c5-3b05-4ff1-f443-7d8f7753dca5"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1013/1013 [==============================] - 70s 63ms/step - loss: 0.1655 - binary_accuracy: 0.9317 - val_loss: 0.1236 - val_binary_accuracy: 0.9472\n","Epoch 2/30\n","1013/1013 [==============================] - 65s 64ms/step - loss: 0.1064 - binary_accuracy: 0.9553 - val_loss: 0.1078 - val_binary_accuracy: 0.9539\n","Epoch 3/30\n","1013/1013 [==============================] - 66s 65ms/step - loss: 0.0882 - binary_accuracy: 0.9628 - val_loss: 0.1017 - val_binary_accuracy: 0.9583\n","Epoch 4/30\n","1013/1013 [==============================] - 67s 66ms/step - loss: 0.0763 - binary_accuracy: 0.9680 - val_loss: 0.0962 - val_binary_accuracy: 0.9614\n","Epoch 5/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0681 - binary_accuracy: 0.9715 - val_loss: 0.0923 - val_binary_accuracy: 0.9634\n","Epoch 6/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0609 - binary_accuracy: 0.9747 - val_loss: 0.0905 - val_binary_accuracy: 0.9652\n","Epoch 7/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0554 - binary_accuracy: 0.9769 - val_loss: 0.0875 - val_binary_accuracy: 0.9667\n","Epoch 8/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0504 - binary_accuracy: 0.9792 - val_loss: 0.0888 - val_binary_accuracy: 0.9669\n","Epoch 9/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0464 - binary_accuracy: 0.9809 - val_loss: 0.0872 - val_binary_accuracy: 0.9683\n","Epoch 10/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0426 - binary_accuracy: 0.9824 - val_loss: 0.0872 - val_binary_accuracy: 0.9690\n","Epoch 11/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0392 - binary_accuracy: 0.9839 - val_loss: 0.0896 - val_binary_accuracy: 0.9695\n","Epoch 12/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0364 - binary_accuracy: 0.9852 - val_loss: 0.0932 - val_binary_accuracy: 0.9696\n","Epoch 13/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0337 - binary_accuracy: 0.9863 - val_loss: 0.0920 - val_binary_accuracy: 0.9705\n","Epoch 14/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0314 - binary_accuracy: 0.9873 - val_loss: 0.0947 - val_binary_accuracy: 0.9706\n","Epoch 15/30\n","1013/1013 [==============================] - 68s 68ms/step - loss: 0.0293 - binary_accuracy: 0.9882 - val_loss: 0.0961 - val_binary_accuracy: 0.9707\n","Epoch 16/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0273 - binary_accuracy: 0.9890 - val_loss: 0.0974 - val_binary_accuracy: 0.9719\n","Epoch 17/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0257 - binary_accuracy: 0.9897 - val_loss: 0.0997 - val_binary_accuracy: 0.9717\n","Epoch 18/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0245 - binary_accuracy: 0.9902 - val_loss: 0.1018 - val_binary_accuracy: 0.9715\n","Epoch 19/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0231 - binary_accuracy: 0.9907 - val_loss: 0.1033 - val_binary_accuracy: 0.9716\n","Epoch 20/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0218 - binary_accuracy: 0.9913 - val_loss: 0.1070 - val_binary_accuracy: 0.9719\n","Epoch 21/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0208 - binary_accuracy: 0.9917 - val_loss: 0.1082 - val_binary_accuracy: 0.9725\n","Epoch 22/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0200 - binary_accuracy: 0.9921 - val_loss: 0.1118 - val_binary_accuracy: 0.9720\n","Epoch 23/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0190 - binary_accuracy: 0.9924 - val_loss: 0.1146 - val_binary_accuracy: 0.9720\n","Epoch 24/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0183 - binary_accuracy: 0.9927 - val_loss: 0.1160 - val_binary_accuracy: 0.9722\n","Epoch 25/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0175 - binary_accuracy: 0.9930 - val_loss: 0.1198 - val_binary_accuracy: 0.9721\n","Epoch 26/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0168 - binary_accuracy: 0.9933 - val_loss: 0.1204 - val_binary_accuracy: 0.9725\n","Epoch 27/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0164 - binary_accuracy: 0.9934 - val_loss: 0.1248 - val_binary_accuracy: 0.9726\n","Epoch 28/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0155 - binary_accuracy: 0.9938 - val_loss: 0.1271 - val_binary_accuracy: 0.9723\n","Epoch 29/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0151 - binary_accuracy: 0.9939 - val_loss: 0.1278 - val_binary_accuracy: 0.9727\n","Epoch 30/30\n","1013/1013 [==============================] - 68s 67ms/step - loss: 0.0150 - binary_accuracy: 0.9940 - val_loss: 0.1289 - val_binary_accuracy: 0.9730\n","Model training done for fold 0\n","125/125 [==============================] - 3s 22ms/step\n","Predictions done for fold 0\n","for fold 0 binary accuracy is:  0.9753333333333346\n","for fold 0 exact match ratio is:  0.84725\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"11Ypfkz64gPX","outputId":"e3634deb-4bb5-43b3-fbd2-74e2b62334b1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711041453711,"user_tz":0,"elapsed":2159993,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1013/1013 [==============================] - 77s 71ms/step - loss: 0.1713 - binary_accuracy: 0.9279 - val_loss: 0.1286 - val_binary_accuracy: 0.9459\n","Epoch 2/30\n","1013/1013 [==============================] - 70s 70ms/step - loss: 0.1092 - binary_accuracy: 0.9536 - val_loss: 0.1057 - val_binary_accuracy: 0.9554\n","Epoch 3/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0895 - binary_accuracy: 0.9622 - val_loss: 0.0991 - val_binary_accuracy: 0.9583\n","Epoch 4/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0776 - binary_accuracy: 0.9674 - val_loss: 0.0965 - val_binary_accuracy: 0.9604\n","Epoch 5/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0692 - binary_accuracy: 0.9710 - val_loss: 0.0920 - val_binary_accuracy: 0.9628\n","Epoch 6/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0627 - binary_accuracy: 0.9739 - val_loss: 0.0919 - val_binary_accuracy: 0.9643\n","Epoch 7/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0569 - binary_accuracy: 0.9761 - val_loss: 0.0892 - val_binary_accuracy: 0.9655\n","Epoch 8/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0521 - binary_accuracy: 0.9783 - val_loss: 0.0917 - val_binary_accuracy: 0.9653\n","Epoch 9/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0477 - binary_accuracy: 0.9801 - val_loss: 0.0897 - val_binary_accuracy: 0.9673\n","Epoch 10/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0443 - binary_accuracy: 0.9816 - val_loss: 0.0886 - val_binary_accuracy: 0.9684\n","Epoch 11/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0414 - binary_accuracy: 0.9829 - val_loss: 0.0904 - val_binary_accuracy: 0.9688\n","Epoch 12/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0385 - binary_accuracy: 0.9841 - val_loss: 0.0916 - val_binary_accuracy: 0.9693\n","Epoch 13/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0359 - binary_accuracy: 0.9851 - val_loss: 0.0932 - val_binary_accuracy: 0.9691\n","Epoch 14/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0341 - binary_accuracy: 0.9858 - val_loss: 0.0943 - val_binary_accuracy: 0.9699\n","Epoch 15/30\n","1013/1013 [==============================] - 70s 70ms/step - loss: 0.0316 - binary_accuracy: 0.9869 - val_loss: 0.0967 - val_binary_accuracy: 0.9703\n","Epoch 16/30\n","1013/1013 [==============================] - 70s 70ms/step - loss: 0.0300 - binary_accuracy: 0.9876 - val_loss: 0.0982 - val_binary_accuracy: 0.9700\n","Epoch 17/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0286 - binary_accuracy: 0.9882 - val_loss: 0.0986 - val_binary_accuracy: 0.9709\n","Epoch 18/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0273 - binary_accuracy: 0.9888 - val_loss: 0.1001 - val_binary_accuracy: 0.9712\n","Epoch 19/30\n","1013/1013 [==============================] - 70s 70ms/step - loss: 0.0256 - binary_accuracy: 0.9895 - val_loss: 0.0989 - val_binary_accuracy: 0.9715\n","Epoch 20/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0246 - binary_accuracy: 0.9899 - val_loss: 0.1006 - val_binary_accuracy: 0.9714\n","Epoch 21/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0237 - binary_accuracy: 0.9903 - val_loss: 0.1053 - val_binary_accuracy: 0.9716\n","Epoch 22/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0227 - binary_accuracy: 0.9908 - val_loss: 0.1040 - val_binary_accuracy: 0.9717\n","Epoch 23/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0219 - binary_accuracy: 0.9910 - val_loss: 0.1068 - val_binary_accuracy: 0.9723\n","Epoch 24/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0209 - binary_accuracy: 0.9914 - val_loss: 0.1106 - val_binary_accuracy: 0.9721\n","Epoch 25/30\n","1013/1013 [==============================] - 70s 70ms/step - loss: 0.0203 - binary_accuracy: 0.9918 - val_loss: 0.1143 - val_binary_accuracy: 0.9718\n","Epoch 26/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0197 - binary_accuracy: 0.9920 - val_loss: 0.1203 - val_binary_accuracy: 0.9726\n","Epoch 27/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0190 - binary_accuracy: 0.9923 - val_loss: 0.1176 - val_binary_accuracy: 0.9719\n","Epoch 28/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0185 - binary_accuracy: 0.9924 - val_loss: 0.1171 - val_binary_accuracy: 0.9726\n","Epoch 29/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0183 - binary_accuracy: 0.9925 - val_loss: 0.1190 - val_binary_accuracy: 0.9718\n","Epoch 30/30\n","1013/1013 [==============================] - 73s 73ms/step - loss: 0.0174 - binary_accuracy: 0.9929 - val_loss: 0.1207 - val_binary_accuracy: 0.9726\n","Model training done for fold 2\n","125/125 [==============================] - 3s 23ms/step\n","Predictions done for fold 2\n","for fold 2 binary accuracy is:  0.9751979166666682\n","for fold 2 exact match ratio is:  0.85075\n"]}],"source":["#3rd fold\n","epochs = 30 # This should be at least 30 for convergence\n","\n","fold_wise_binary_accuracy=[]\n","fold_wise_exact_match=[]\n","\n","#for i in range(1):\n","for i in range(2, 3):\n","    model.compile(keras.optimizers.Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","\n","    model.fit(X_train[i],Y_train[i], epochs= epochs, validation_split=0.1)\n","\n","    print('Model training done for fold '+str(i))\n","    predictions=model.predict(X_test[i])\n","    print('Predictions done for fold '+str(i))\n","\n","    bins = np.array([0.5])\n","    count_exact_match=0\n","    sum_acc=0\n","\n","    for j in range(len(predictions)):\n","        discrete_prediction=np.digitize(predictions[j], bins)\n","        acc=accuracy_score(Y_test[i][j],discrete_prediction)\n","        sum_acc=sum_acc+acc\n","        if acc==1:\n","            count_exact_match=count_exact_match+1\n","    avg_acc=sum_acc/len(predictions)\n","    exact_match_ratio=count_exact_match/len(predictions)\n","\n","    fold_wise_binary_accuracy.append(avg_acc)\n","    fold_wise_exact_match.append(exact_match_ratio)\n","\n","    print('for fold '+ str(i)+' binary accuracy is: ', avg_acc)\n","    print('for fold '+ str(i)+' exact match ratio is: ', exact_match_ratio)\n"]},{"cell_type":"code","source":["#Re run the below code"],"metadata":{"id":"7W1iLItOJP_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pG0rdORf4gPX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d1b56e92-223b-42f3-d218-9ab1b5b155e6","executionInfo":{"status":"ok","timestamp":1711163147595,"user_tz":0,"elapsed":2253645,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1013/1013 [==============================] - 80s 72ms/step - loss: 0.0241 - binary_accuracy: 0.9902 - val_loss: 0.1031 - val_binary_accuracy: 0.9720\n","Epoch 2/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0226 - binary_accuracy: 0.9907 - val_loss: 0.1034 - val_binary_accuracy: 0.9721\n","Epoch 3/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0213 - binary_accuracy: 0.9913 - val_loss: 0.1061 - val_binary_accuracy: 0.9725\n","Epoch 4/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0205 - binary_accuracy: 0.9914 - val_loss: 0.1085 - val_binary_accuracy: 0.9723\n","Epoch 5/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0197 - binary_accuracy: 0.9920 - val_loss: 0.1072 - val_binary_accuracy: 0.9729\n","Epoch 6/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0194 - binary_accuracy: 0.9922 - val_loss: 0.1121 - val_binary_accuracy: 0.9727\n","Epoch 7/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0188 - binary_accuracy: 0.9924 - val_loss: 0.1142 - val_binary_accuracy: 0.9720\n","Epoch 8/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0180 - binary_accuracy: 0.9928 - val_loss: 0.1123 - val_binary_accuracy: 0.9728\n","Epoch 9/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0178 - binary_accuracy: 0.9928 - val_loss: 0.1166 - val_binary_accuracy: 0.9721\n","Epoch 10/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0171 - binary_accuracy: 0.9930 - val_loss: 0.1174 - val_binary_accuracy: 0.9724\n","Epoch 11/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0167 - binary_accuracy: 0.9932 - val_loss: 0.1229 - val_binary_accuracy: 0.9726\n","Epoch 12/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0167 - binary_accuracy: 0.9932 - val_loss: 0.1235 - val_binary_accuracy: 0.9729\n","Epoch 13/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0159 - binary_accuracy: 0.9937 - val_loss: 0.1229 - val_binary_accuracy: 0.9727\n","Epoch 14/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0155 - binary_accuracy: 0.9938 - val_loss: 0.1241 - val_binary_accuracy: 0.9736\n","Epoch 15/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0152 - binary_accuracy: 0.9939 - val_loss: 0.1242 - val_binary_accuracy: 0.9732\n","Epoch 16/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0150 - binary_accuracy: 0.9940 - val_loss: 0.1297 - val_binary_accuracy: 0.9732\n","Epoch 17/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0145 - binary_accuracy: 0.9941 - val_loss: 0.1300 - val_binary_accuracy: 0.9737\n","Epoch 18/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0145 - binary_accuracy: 0.9942 - val_loss: 0.1337 - val_binary_accuracy: 0.9728\n","Epoch 19/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0142 - binary_accuracy: 0.9942 - val_loss: 0.1352 - val_binary_accuracy: 0.9734\n","Epoch 20/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0139 - binary_accuracy: 0.9944 - val_loss: 0.1325 - val_binary_accuracy: 0.9727\n","Epoch 21/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0134 - binary_accuracy: 0.9947 - val_loss: 0.1362 - val_binary_accuracy: 0.9742\n","Epoch 22/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0132 - binary_accuracy: 0.9947 - val_loss: 0.1372 - val_binary_accuracy: 0.9734\n","Epoch 23/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0133 - binary_accuracy: 0.9947 - val_loss: 0.1364 - val_binary_accuracy: 0.9735\n","Epoch 24/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0127 - binary_accuracy: 0.9950 - val_loss: 0.1385 - val_binary_accuracy: 0.9737\n","Epoch 25/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0126 - binary_accuracy: 0.9950 - val_loss: 0.1422 - val_binary_accuracy: 0.9733\n","Epoch 26/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0128 - binary_accuracy: 0.9949 - val_loss: 0.1418 - val_binary_accuracy: 0.9734\n","Epoch 27/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0122 - binary_accuracy: 0.9950 - val_loss: 0.1438 - val_binary_accuracy: 0.9737\n","Epoch 28/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0121 - binary_accuracy: 0.9951 - val_loss: 0.1462 - val_binary_accuracy: 0.9734\n","Epoch 29/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0117 - binary_accuracy: 0.9954 - val_loss: 0.1435 - val_binary_accuracy: 0.9736\n","Epoch 30/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0120 - binary_accuracy: 0.9952 - val_loss: 0.1469 - val_binary_accuracy: 0.9737\n","Model training done for fold 4\n","125/125 [==============================] - 3s 23ms/step\n","Predictions done for fold 4\n","for fold 4 binary accuracy is:  0.9765416666666676\n","for fold 4 exact match ratio is:  0.85575\n"]}],"source":["#5th fold\n","epochs = 30 # This should be at least 30 for convergence\n","\n","fold_wise_binary_accuracy=[]\n","fold_wise_exact_match=[]\n","\n","#for i in range(1):\n","for i in range(4, 5):\n","    model.compile(keras.optimizers.Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","\n","    model.fit(X_train[i],Y_train[i], epochs= epochs, validation_split=0.1)\n","\n","    print('Model training done for fold '+str(i))\n","    predictions=model.predict(X_test[i])\n","    print('Predictions done for fold '+str(i))\n","\n","    bins = np.array([0.5])\n","    count_exact_match=0\n","    sum_acc=0\n","\n","    for j in range(len(predictions)):\n","        discrete_prediction=np.digitize(predictions[j], bins)\n","        acc=accuracy_score(Y_test[i][j],discrete_prediction)\n","        sum_acc=sum_acc+acc\n","        if acc==1:\n","            count_exact_match=count_exact_match+1\n","    avg_acc=sum_acc/len(predictions)\n","    exact_match_ratio=count_exact_match/len(predictions)\n","\n","    fold_wise_binary_accuracy.append(avg_acc)\n","    fold_wise_exact_match.append(exact_match_ratio)\n","\n","    print('for fold '+ str(i)+' binary accuracy is: ', avg_acc)\n","    print('for fold '+ str(i)+' exact match ratio is: ', exact_match_ratio)\n"]},{"cell_type":"code","source":["#7th fold\n","epochs = 30 # This should be at least 30 for convergence\n","\n","fold_wise_binary_accuracy=[]\n","fold_wise_exact_match=[]\n","\n","#for i in range(1):\n","for i in range(6, 7):\n","    model.compile(keras.optimizers.Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","\n","    model.fit(X_train[i],Y_train[i], epochs= epochs, validation_split=0.1)\n","\n","    print('Model training done for fold '+str(i))\n","    predictions=model.predict(X_test[i])\n","    print('Predictions done for fold '+str(i))\n","\n","    bins = np.array([0.5])\n","    count_exact_match=0\n","    sum_acc=0\n","\n","    for j in range(len(predictions)):\n","        discrete_prediction=np.digitize(predictions[j], bins)\n","        acc=accuracy_score(Y_test[i][j],discrete_prediction)\n","        sum_acc=sum_acc+acc\n","        if acc==1:\n","            count_exact_match=count_exact_match+1\n","    avg_acc=sum_acc/len(predictions)\n","    exact_match_ratio=count_exact_match/len(predictions)\n","\n","    fold_wise_binary_accuracy.append(avg_acc)\n","    fold_wise_exact_match.append(exact_match_ratio)\n","\n","    print('for fold '+ str(i)+' binary accuracy is: ', avg_acc)\n","    print('for fold '+ str(i)+' exact match ratio is: ', exact_match_ratio)\n"],"metadata":{"id":"GSJpQAzyBZGI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711274399770,"user_tz":0,"elapsed":2253695,"user":{"displayName":"VARUN RAJ S - IMS20240","userId":"14429748007435380283"}},"outputId":"b62dd79c-c219-4f29-dd44-3cd2ed63644d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1013/1013 [==============================] - 83s 70ms/step - loss: 0.1819 - binary_accuracy: 0.9228 - val_loss: 0.1426 - val_binary_accuracy: 0.9379\n","Epoch 2/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.1186 - binary_accuracy: 0.9486 - val_loss: 0.1166 - val_binary_accuracy: 0.9499\n","Epoch 3/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0961 - binary_accuracy: 0.9588 - val_loss: 0.1031 - val_binary_accuracy: 0.9571\n","Epoch 4/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0831 - binary_accuracy: 0.9648 - val_loss: 0.0990 - val_binary_accuracy: 0.9595\n","Epoch 5/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0742 - binary_accuracy: 0.9690 - val_loss: 0.0955 - val_binary_accuracy: 0.9615\n","Epoch 6/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0673 - binary_accuracy: 0.9720 - val_loss: 0.0940 - val_binary_accuracy: 0.9623\n","Epoch 7/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0612 - binary_accuracy: 0.9747 - val_loss: 0.0894 - val_binary_accuracy: 0.9657\n","Epoch 8/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0562 - binary_accuracy: 0.9765 - val_loss: 0.0932 - val_binary_accuracy: 0.9657\n","Epoch 9/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0520 - binary_accuracy: 0.9784 - val_loss: 0.0891 - val_binary_accuracy: 0.9672\n","Epoch 10/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0482 - binary_accuracy: 0.9799 - val_loss: 0.0901 - val_binary_accuracy: 0.9678\n","Epoch 11/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0446 - binary_accuracy: 0.9813 - val_loss: 0.0944 - val_binary_accuracy: 0.9679\n","Epoch 12/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0420 - binary_accuracy: 0.9825 - val_loss: 0.0902 - val_binary_accuracy: 0.9692\n","Epoch 13/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0392 - binary_accuracy: 0.9839 - val_loss: 0.0910 - val_binary_accuracy: 0.9687\n","Epoch 14/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0369 - binary_accuracy: 0.9847 - val_loss: 0.0922 - val_binary_accuracy: 0.9694\n","Epoch 15/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0348 - binary_accuracy: 0.9854 - val_loss: 0.0917 - val_binary_accuracy: 0.9702\n","Epoch 16/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0328 - binary_accuracy: 0.9863 - val_loss: 0.0922 - val_binary_accuracy: 0.9705\n","Epoch 17/30\n","1013/1013 [==============================] - 74s 73ms/step - loss: 0.0312 - binary_accuracy: 0.9871 - val_loss: 0.0945 - val_binary_accuracy: 0.9705\n","Epoch 18/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0297 - binary_accuracy: 0.9877 - val_loss: 0.0968 - val_binary_accuracy: 0.9709\n","Epoch 19/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0282 - binary_accuracy: 0.9884 - val_loss: 0.0981 - val_binary_accuracy: 0.9708\n","Epoch 20/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0271 - binary_accuracy: 0.9887 - val_loss: 0.1023 - val_binary_accuracy: 0.9709\n","Epoch 21/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0259 - binary_accuracy: 0.9893 - val_loss: 0.1034 - val_binary_accuracy: 0.9713\n","Epoch 22/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0251 - binary_accuracy: 0.9897 - val_loss: 0.1046 - val_binary_accuracy: 0.9711\n","Epoch 23/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0241 - binary_accuracy: 0.9900 - val_loss: 0.1083 - val_binary_accuracy: 0.9709\n","Epoch 24/30\n","1013/1013 [==============================] - 72s 72ms/step - loss: 0.0234 - binary_accuracy: 0.9903 - val_loss: 0.1058 - val_binary_accuracy: 0.9716\n","Epoch 25/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0228 - binary_accuracy: 0.9906 - val_loss: 0.1101 - val_binary_accuracy: 0.9712\n","Epoch 26/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0219 - binary_accuracy: 0.9909 - val_loss: 0.1130 - val_binary_accuracy: 0.9708\n","Epoch 27/30\n","1013/1013 [==============================] - 73s 72ms/step - loss: 0.0214 - binary_accuracy: 0.9911 - val_loss: 0.1123 - val_binary_accuracy: 0.9720\n","Epoch 28/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0210 - binary_accuracy: 0.9913 - val_loss: 0.1164 - val_binary_accuracy: 0.9712\n","Epoch 29/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0204 - binary_accuracy: 0.9915 - val_loss: 0.1162 - val_binary_accuracy: 0.9716\n","Epoch 30/30\n","1013/1013 [==============================] - 75s 74ms/step - loss: 0.0199 - binary_accuracy: 0.9917 - val_loss: 0.1165 - val_binary_accuracy: 0.9724\n","Model training done for fold 6\n","125/125 [==============================] - 3s 22ms/step\n","Predictions done for fold 6\n","for fold 6 binary accuracy is:  0.9721354166666669\n","for fold 6 exact match ratio is:  0.839\n"]}]},{"cell_type":"code","source":["#9th fold\n","epochs = 30 # This should be at least 30 for convergence\n","\n","fold_wise_binary_accuracy=[]\n","fold_wise_exact_match=[]\n","\n","#for i in range(1):\n","for i in range(8, 9):\n","    model.compile(keras.optimizers.Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","\n","    model.fit(X_train[i],Y_train[i], epochs= epochs, validation_split=0.1)\n","\n","    print('Model training done for fold '+str(i))\n","    predictions=model.predict(X_test[i])\n","    print('Predictions done for fold '+str(i))\n","\n","    bins = np.array([0.5])\n","    count_exact_match=0\n","    sum_acc=0\n","\n","    for j in range(len(predictions)):\n","        discrete_prediction=np.digitize(predictions[j], bins)\n","        acc=accuracy_score(Y_test[i][j],discrete_prediction)\n","        sum_acc=sum_acc+acc\n","        if acc==1:\n","            count_exact_match=count_exact_match+1\n","    avg_acc=sum_acc/len(predictions)\n","    exact_match_ratio=count_exact_match/len(predictions)\n","\n","    fold_wise_binary_accuracy.append(avg_acc)\n","    fold_wise_exact_match.append(exact_match_ratio)\n","\n","    print('for fold '+ str(i)+' binary accuracy is: ', avg_acc)\n","    print('for fold '+ str(i)+' exact match ratio is: ', exact_match_ratio)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZD6MM4pHxK3F","outputId":"2cca3624-8c4a-4c15-e16c-b8f2c393e5a5","executionInfo":{"status":"ok","timestamp":1711282949308,"user_tz":-330,"elapsed":2191076,"user":{"displayName":"DHARUN J - IMS20096","userId":"04137242427018088914"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1013/1013 [==============================] - 78s 71ms/step - loss: 0.1689 - binary_accuracy: 0.9294 - val_loss: 0.1300 - val_binary_accuracy: 0.9459\n","Epoch 2/30\n","1013/1013 [==============================] - 69s 68ms/step - loss: 0.1098 - binary_accuracy: 0.9546 - val_loss: 0.1127 - val_binary_accuracy: 0.9528\n","Epoch 3/30\n","1013/1013 [==============================] - 71s 70ms/step - loss: 0.0908 - binary_accuracy: 0.9627 - val_loss: 0.1040 - val_binary_accuracy: 0.9567\n","Epoch 4/30\n","1013/1013 [==============================] - 69s 69ms/step - loss: 0.0789 - binary_accuracy: 0.9677 - val_loss: 0.0991 - val_binary_accuracy: 0.9608\n","Epoch 5/30\n","1013/1013 [==============================] - 69s 68ms/step - loss: 0.0705 - binary_accuracy: 0.9712 - val_loss: 0.0925 - val_binary_accuracy: 0.9635\n","Epoch 6/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0642 - binary_accuracy: 0.9738 - val_loss: 0.0918 - val_binary_accuracy: 0.9643\n","Epoch 7/30\n","1013/1013 [==============================] - 69s 68ms/step - loss: 0.0584 - binary_accuracy: 0.9762 - val_loss: 0.0900 - val_binary_accuracy: 0.9658\n","Epoch 8/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0541 - binary_accuracy: 0.9779 - val_loss: 0.0892 - val_binary_accuracy: 0.9666\n","Epoch 9/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0495 - binary_accuracy: 0.9799 - val_loss: 0.0927 - val_binary_accuracy: 0.9666\n","Epoch 10/30\n","1013/1013 [==============================] - 70s 69ms/step - loss: 0.0457 - binary_accuracy: 0.9812 - val_loss: 0.0879 - val_binary_accuracy: 0.9685\n","Epoch 11/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0420 - binary_accuracy: 0.9828 - val_loss: 0.0899 - val_binary_accuracy: 0.9689\n","Epoch 12/30\n","1013/1013 [==============================] - 70s 69ms/step - loss: 0.0391 - binary_accuracy: 0.9842 - val_loss: 0.0901 - val_binary_accuracy: 0.9700\n","Epoch 13/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0363 - binary_accuracy: 0.9854 - val_loss: 0.0912 - val_binary_accuracy: 0.9704\n","Epoch 14/30\n","1013/1013 [==============================] - 70s 69ms/step - loss: 0.0342 - binary_accuracy: 0.9862 - val_loss: 0.0941 - val_binary_accuracy: 0.9704\n","Epoch 15/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0319 - binary_accuracy: 0.9871 - val_loss: 0.0935 - val_binary_accuracy: 0.9712\n","Epoch 16/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0301 - binary_accuracy: 0.9878 - val_loss: 0.0938 - val_binary_accuracy: 0.9712\n","Epoch 17/30\n","1013/1013 [==============================] - 70s 69ms/step - loss: 0.0284 - binary_accuracy: 0.9887 - val_loss: 0.1001 - val_binary_accuracy: 0.9709\n","Epoch 18/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0269 - binary_accuracy: 0.9892 - val_loss: 0.0982 - val_binary_accuracy: 0.9717\n","Epoch 19/30\n","1013/1013 [==============================] - 70s 69ms/step - loss: 0.0253 - binary_accuracy: 0.9899 - val_loss: 0.1011 - val_binary_accuracy: 0.9717\n","Epoch 20/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0240 - binary_accuracy: 0.9903 - val_loss: 0.1033 - val_binary_accuracy: 0.9717\n","Epoch 21/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0231 - binary_accuracy: 0.9907 - val_loss: 0.1051 - val_binary_accuracy: 0.9717\n","Epoch 22/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0222 - binary_accuracy: 0.9911 - val_loss: 0.1080 - val_binary_accuracy: 0.9721\n","Epoch 23/30\n","1013/1013 [==============================] - 69s 68ms/step - loss: 0.0212 - binary_accuracy: 0.9915 - val_loss: 0.1095 - val_binary_accuracy: 0.9724\n","Epoch 24/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0202 - binary_accuracy: 0.9919 - val_loss: 0.1116 - val_binary_accuracy: 0.9721\n","Epoch 25/30\n","1013/1013 [==============================] - 69s 68ms/step - loss: 0.0194 - binary_accuracy: 0.9923 - val_loss: 0.1151 - val_binary_accuracy: 0.9723\n","Epoch 26/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0190 - binary_accuracy: 0.9924 - val_loss: 0.1162 - val_binary_accuracy: 0.9724\n","Epoch 27/30\n","1013/1013 [==============================] - 69s 68ms/step - loss: 0.0180 - binary_accuracy: 0.9928 - val_loss: 0.1170 - val_binary_accuracy: 0.9727\n","Epoch 28/30\n","1013/1013 [==============================] - 69s 69ms/step - loss: 0.0179 - binary_accuracy: 0.9928 - val_loss: 0.1199 - val_binary_accuracy: 0.9723\n","Epoch 29/30\n","1013/1013 [==============================] - 72s 71ms/step - loss: 0.0175 - binary_accuracy: 0.9929 - val_loss: 0.1205 - val_binary_accuracy: 0.9730\n","Epoch 30/30\n","1013/1013 [==============================] - 69s 68ms/step - loss: 0.0164 - binary_accuracy: 0.9935 - val_loss: 0.1231 - val_binary_accuracy: 0.9727\n","Model training done for fold 8\n","125/125 [==============================] - 3s 22ms/step\n","Predictions done for fold 8\n","for fold 8 binary accuracy is:  0.9743958333333343\n","for fold 8 exact match ratio is:  0.844\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cqzimP5k6qYl"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}